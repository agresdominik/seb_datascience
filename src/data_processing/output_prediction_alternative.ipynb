{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/project/seb_datascience/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import median_filter\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "from wOpenTimes import ( \n",
    "    WINDOW_OPEN_TIMES\n",
    ")\n",
    "\n",
    "results_df = pd.DataFrame\n",
    "data = pd.DataFrame\n",
    "time_to_23_degrees = []\n",
    "\n",
    "def main():\n",
    "\n",
    "    global data\n",
    "    global time_to_23_degrees\n",
    "\n",
    "    data_list = read_collected_data()\n",
    "    inside_temp_data = data_list[0]\n",
    "    outside_temp_data = data_list[1]\n",
    "    outside_humidity_data = data_list[2]\n",
    "    inside_humidity_data = data_list[3]\n",
    "\n",
    "    inside_temp_data = normalize_data(inside_temp_data, \"temperature\")\n",
    "    outside_temp_data = normalize_data(outside_temp_data, \"temperature\")\n",
    "\n",
    "    inside_humidity_data = normalize_data(inside_humidity_data, \"humidity\")\n",
    "    outside_humidity_data = normalize_data(outside_humidity_data, \"humidity\")\n",
    "\n",
    "    data = pd.merge_asof(inside_temp_data.sort_values('Time'), \n",
    "                     outside_temp_data.sort_values('Time'), \n",
    "                     on='Time', \n",
    "                     suffixes=('_inside', '_outside'))\n",
    "\n",
    "    data = data.dropna()\n",
    "\n",
    "    span = 12  # Determines the degree of smoothing\n",
    "    data['Temperature_inside'] = data['Temperature_inside'].ewm(span=span, adjust=False).mean()\n",
    "    \n",
    "    window_open_times = [datetime.strptime(t, '%Y-%m-%d %H:%M:%S') for t in WINDOW_OPEN_TIMES]\n",
    "    data['Time'] = pd.to_datetime(data['Time'])\n",
    "    data['Window_Open'] = 0\n",
    "\n",
    "    for start_time in window_open_times:\n",
    "        end_time = start_time + timedelta(minutes=31)\n",
    "        data.loc[(data['Time'] >= start_time) & (data['Time'] < end_time), 'Window_Open'] = 1\n",
    "\n",
    "    data[\"Minutes_to_24\"] = np.nan\n",
    "    counter = 0\n",
    "    goal_temperature = 24\n",
    "\n",
    "    for index, row in data.iloc[::-1].iterrows():\n",
    "\n",
    "        if row['Window_Open'] == 0:\n",
    "            counter = 0\n",
    "            continue\n",
    "        elif row['Temperature_inside'] >= goal_temperature and row['Window_Open'] == 1:\n",
    "            counter += 1\n",
    "            data.at[index, 'Minutes_to_24'] = counter\n",
    "            \n",
    "    data = data.dropna(subset=['Minutes_to_24'])\n",
    "\n",
    "    X = data[['Temperature_inside', 'Temperature_outside', 'Window_Open']].astype(float)\n",
    "    y = data['Minutes_to_24']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'lbfgs'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate_init': [0.001, 0.01]\n",
    "    }\n",
    "\n",
    "    # Create and train the model\n",
    "    model = MLPRegressor(\n",
    "        #hidden_layer_sizes=(50, 25),\n",
    "        #activation='relu',\n",
    "        #solver='adam',\n",
    "        max_iter=5000,\n",
    "        random_state=42\n",
    "        )\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    #model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "    # Evaluate the model\n",
    "    #y_pred = model.predict(X_test)\n",
    "    #mse = mean_squared_error(y_test, y_pred)\n",
    "    #r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    #print(f\"Mean Squared Error: {mse}\")\n",
    "    #print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "    # Example prediction\n",
    "    #example_input = np.array([[25.6, 2.7, 1]])  # [temperature_inside, temperature_outside, window_is_open]\n",
    "\n",
    "    #predicted_time = model.predict(example_input)\n",
    "    #print(f\"Predicted time to reach 24째C: {predicted_time[0]:.2f} minutes\")\n",
    "\n",
    "\n",
    "\n",
    "def write_data_to_csv(data_frame: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    This function writes the data to a csv file.\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    #timestamp_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    file_name = f\"analasys_output_temperature.csv\"\n",
    "    data_frame.to_csv(file_name, index=False)\n",
    "\n",
    "\n",
    "def read_collected_data() -> list[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    This function reads the collected data from the csv files and returns a list of two dataframes.\n",
    "    The dataframes are labeled, their data is interpolated and resampled to 1 minute intervals.\n",
    "    \"\"\"\n",
    "    \n",
    "    inside_temp_data = pd.read_csv('/project/seb_datascience/src/data_processing/data/inside_temperature.csv', parse_dates=['Time'])\n",
    "    inside_temp_data = inside_temp_data.iloc[1:].reset_index(drop=True)\n",
    "    inside_temp_data.columns = ['Time', 'Temperature']\n",
    "    inside_temp_data['Temperature'] = inside_temp_data['Temperature'].str.replace(' 째C', '', regex=False).str.strip()\n",
    "    inside_temp_data['Temperature'] = pd.to_numeric(inside_temp_data['Temperature'], errors='coerce')\n",
    "\n",
    "    outside_temp_data = pd.read_csv('/project/seb_datascience/src/data_processing/data/outside_temperature.csv', parse_dates=['Time'])\n",
    "    outside_temp_data = outside_temp_data.iloc[1:].reset_index(drop=True)\n",
    "    outside_temp_data.columns = ['Time', 'Temperature']\n",
    "    outside_temp_data['Temperature'] = outside_temp_data['Temperature'].str.replace(' 째C', '', regex=False).str.strip()\n",
    "    outside_temp_data['Temperature'] = pd.to_numeric(outside_temp_data['Temperature'], errors='coerce')\n",
    "\n",
    "    inside_humidity_data = pd.read_csv('/project/seb_datascience/src/data_processing/data/inside_humidity.csv', parse_dates=['Time'])\n",
    "    inside_humidity_data = inside_humidity_data.iloc[1:].reset_index(drop=True)\n",
    "    inside_humidity_data['Humidity'] = inside_humidity_data['Humidity'].str.replace(' %', '', regex=False).str.strip()\n",
    "    inside_humidity_data['Humidity'] = pd.to_numeric(inside_humidity_data['Humidity'], errors='coerce')\n",
    "\n",
    "    outside_humidity_data = pd.read_csv('/project/seb_datascience/src/data_processing/data/outside_humidity.csv', parse_dates=['Time'])\n",
    "    outside_humidity_data = outside_humidity_data.iloc[1:].reset_index(drop=True)\n",
    "    outside_humidity_data['Humidity'] = outside_humidity_data['Humidity'].str.replace(' %', '', regex=False).str.strip()\n",
    "    outside_humidity_data['Humidity'] = pd.to_numeric(outside_humidity_data['Humidity'], errors='coerce')\n",
    "\n",
    "    outside_temp_data = outside_temp_data.set_index('Time').resample('1T').interpolate('linear').reset_index()\n",
    "    inside_temp_data = inside_temp_data.set_index('Time').resample('1T').interpolate('linear').reset_index()\n",
    "    inside_humidity_data = inside_humidity_data.set_index('Time').resample('1T').interpolate('linear').reset_index()\n",
    "    outside_humidity_data = outside_humidity_data.set_index('Time').resample('1T').interpolate('linear').reset_index()\n",
    "\n",
    "    data_list = [inside_temp_data, outside_temp_data, outside_humidity_data, inside_humidity_data]\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def normalize_data(data_frame: pd.DataFrame, file_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function normalizes the data by removing outliers and interpolating the data to 1 minute intervals.\n",
    "    \"\"\"\n",
    "\n",
    "    if file_type == \"temperature\":\n",
    "        value = \"Temperature\"\n",
    "        lower_percentile = 0.01\n",
    "        upper_percentile = 99.99\n",
    "    elif file_type == \"humidity\":\n",
    "        value = \"Humidity\"\n",
    "        lower_percentile = 0.1\n",
    "        upper_percentile = 99.9\n",
    "    else:\n",
    "        raise ValueError(\"Invalid file type\")\n",
    "\n",
    "    lower_threshold = data_frame[value].quantile(lower_percentile / 100)\n",
    "    upper_threshold = data_frame[value].quantile(upper_percentile / 100)\n",
    "\n",
    "    df_filtered = data_frame[(data_frame[value] >= lower_threshold) & (data_frame[value] <= upper_threshold)]\n",
    "    df_filtered = df_filtered.set_index('Time').resample('1T').interpolate('linear').reset_index()\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def try_different_times(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "\n",
    "    for i in range(1, 40):\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for start in WINDOW_OPEN_TIMES:\n",
    "\n",
    "            try:\n",
    "\n",
    "                start_time = pd.to_datetime(start)\n",
    "                defined_time_later = start_time + pd.Timedelta(minutes=i)\n",
    "\n",
    "                temp_at_start = data.loc[data['Time'] == start_time, 'Temperature_inside'].values[0]\n",
    "                outside_temp_at_start = data.loc[data['Time'] == start_time, 'Temperature_outside'].values[0]\n",
    "                \n",
    "                temp_after_defined_time = data.loc[data['Time'] == defined_time_later, 'Temperature_inside'].values[0]\n",
    "                outside_temp_after_defined_time = data.loc[data['Time'] == defined_time_later, 'Temperature_outside'].values[0]\n",
    "                \n",
    "                temp_drop = temp_at_start - temp_after_defined_time\n",
    "\n",
    "                temp_difference_at_start = temp_at_start - outside_temp_at_start\n",
    "                temp_difference_at_end = temp_after_defined_time - outside_temp_after_defined_time\n",
    "                average_temp_difference = (temp_difference_at_start + temp_difference_at_end) / 2\n",
    "\n",
    "                cooling_rate = (temp_difference_at_start - temp_difference_at_end) / i\n",
    "                results.append({'temp_difference_at_start': temp_difference_at_start, 'temp_difference_at_end': temp_difference_at_end, 'average_temp_difference': average_temp_difference, 'cooling_rate': cooling_rate})\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                data.to_csv(\"error_dump.csv\", index=False)\n",
    "                print(f\"Error processing data for window open time: {start}, Exception: {e}\")\n",
    "\n",
    "        results_df_for_test = pd.DataFrame(results)\n",
    "        results_df_for_test = results_df_for_test.round(3)\n",
    "        \n",
    "\n",
    "        #collerate_data = results_df_for_test[['temp_difference_at_start', 'cooling_rate']]\n",
    "        print(f\"Correlation for {i} minutes: \")\n",
    "        print(results_df_for_test.corr())\n",
    "        #print(collerate_data.corr())\n",
    "\n",
    "\n",
    "def experiment_with_values(data):\n",
    "    # Assuming df has columns: 'Time', 'indoor_temp', 'outdoor_temp'\n",
    "    data['Time'] = pd.to_datetime(data['Time'])  # Ensure the Time column is datetime type\n",
    "\n",
    "    # Calculate the difference in indoor temperature\n",
    "    data['delta_indoor'] = data['Temperature_inside'].diff()\n",
    "\n",
    "    # Define a threshold for a high drop in temperature (e.g., -1.5째C)\n",
    "    threshold_drop = -1\n",
    "    threshold_rise = 1  # The temperature rise threshold to mark the window as closed\n",
    "    buffer_measurements = 10  # Number of consecutive measurements to check for a rise in temperature\n",
    "\n",
    "    # Initialize the 'window_open' column\n",
    "    data['window_open'] = False\n",
    "\n",
    "    # Step 1: Detect steep drops\n",
    "    for i in range(1, len(data)):\n",
    "        if data['delta_indoor'].iloc[i] < threshold_drop:  # Check for a steep drop\n",
    "            data.loc[i, 'window_open'] = True  # Mark as window open\n",
    "\n",
    "            # Step 2: Sustain the window open state until temperature rises\n",
    "            # Check if temperature starts rising continuously for more than 'buffer_measurements' consecutive points\n",
    "            for j in range(i + 1, len(data)):\n",
    "                if data['Temperature_inside'].iloc[j] - data['Temperature_inside'].iloc[j-1] > threshold_rise:\n",
    "                    consecutive_rises = 0\n",
    "                    for k in range(j, len(data)):\n",
    "                        if data['Temperature_inside'].iloc[k] - data['Temperature_inside'].iloc[k-1] > threshold_rise:\n",
    "                            consecutive_rises += 1\n",
    "                        else:\n",
    "                            break\n",
    "                    if consecutive_rises >= buffer_measurements:\n",
    "                        # Mark window as closed after sustained rise\n",
    "                        data.loc[i:j, 'window_open'] = False\n",
    "                        break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
